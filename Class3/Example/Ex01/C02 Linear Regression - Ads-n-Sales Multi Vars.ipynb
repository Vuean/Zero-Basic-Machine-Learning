{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wechat</th>\n",
       "      <th>weibo</th>\n",
       "      <th>others</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>304.4</td>\n",
       "      <td>93.6</td>\n",
       "      <td>294.4</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1011.9</td>\n",
       "      <td>34.4</td>\n",
       "      <td>398.4</td>\n",
       "      <td>16.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1091.1</td>\n",
       "      <td>32.8</td>\n",
       "      <td>295.2</td>\n",
       "      <td>17.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85.5</td>\n",
       "      <td>173.6</td>\n",
       "      <td>403.2</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1047.0</td>\n",
       "      <td>302.4</td>\n",
       "      <td>553.6</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wechat  weibo  others  sales\n",
       "0   304.4   93.6   294.4    9.7\n",
       "1  1011.9   34.4   398.4   16.7\n",
       "2  1091.1   32.8   295.2   17.3\n",
       "3    85.5  173.6   403.2    7.0\n",
       "4  1047.0  302.4   553.6   22.1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_ads = pd.read_csv('./dataset/advertising.csv')\n",
    "df_ads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "张量X的阶: 2\n",
      "张量X的形状: (200, 3)\n",
      "[[ 304.4   93.6  294.4]\n",
      " [1011.9   34.4  398.4]\n",
      " [1091.1   32.8  295.2]\n",
      " [  85.5  173.6  403.2]\n",
      " [1047.   302.4  553.6]\n",
      " [ 940.9   41.6  155.2]\n",
      " [1277.2  111.2  296. ]\n",
      " [  38.2  217.6   16.8]\n",
      " [ 342.6  162.4  260. ]\n",
      " [ 347.6    6.4  118.4]\n",
      " [ 980.1  188.8  460.8]\n",
      " [  39.1   16.8    8. ]\n",
      " [  39.6  391.2  600. ]\n",
      " [ 889.1  381.6  423.2]\n",
      " [ 633.8  116.    81.6]\n",
      " [ 527.8   61.6  184.8]\n",
      " [ 203.4  206.4  164.8]\n",
      " [ 499.6  382.4  411.2]\n",
      " [ 633.4  114.4  204.8]\n",
      " [ 437.7  118.4  311.2]\n",
      " [ 334.   136.   103.2]\n",
      " [1132.   216.8  183.2]\n",
      " [ 841.3  351.2   13.6]\n",
      " [ 435.4   11.2   59.2]\n",
      " [ 627.4  371.2  472. ]\n",
      " [ 599.2  147.2  276.8]\n",
      " [ 321.2  128.   326.4]\n",
      " [ 571.9  295.2  633.6]\n",
      " [ 758.9  336.    28.8]\n",
      " [ 799.4  123.2   19.2]\n",
      " [ 314.    74.4    7.2]\n",
      " [ 108.3  280.8  527.2]\n",
      " [ 339.9  395.2  365.6]\n",
      " [ 619.7  153.6  132.8]\n",
      " [ 227.5   92.8  147.2]\n",
      " [ 347.2  220.   128. ]\n",
      " [ 774.4   62.4  281.6]\n",
      " [1003.3  265.6  303.2]\n",
      " [  60.1  127.2  396.8]\n",
      " [  88.3  128.   178.4]\n",
      " [1280.4  316.8  446.4]\n",
      " [ 743.9  294.4   59.2]\n",
      " [ 805.4  267.2  309.6]\n",
      " [ 905.   395.2  480. ]\n",
      " [  76.9  349.6  715.2]\n",
      " [1088.8  124.   218.4]\n",
      " [ 670.2  191.2  152.8]\n",
      " [ 513.7  139.2  308.8]\n",
      " [1067.    27.2  678.4]\n",
      " [  89.2  160.8  136. ]\n",
      " [ 130.1   12.   264. ]\n",
      " [ 113.8   88.   237.6]\n",
      " [ 195.7  207.2  164. ]\n",
      " [1000.1  268.   360.8]\n",
      " [ 283.5  100.8  146.4]\n",
      " [1245.3  231.2  477.6]\n",
      " [ 681.1  284.8   48. ]\n",
      " [ 341.7  280.   421.6]\n",
      " [ 743.   252.8  423.2]\n",
      " [ 976.9  192.    32. ]\n",
      " [1308.6  344.   574.4]\n",
      " [ 953.7  164.8   85.6]\n",
      " [1196.2   28.   156. ]\n",
      " [ 488.7  112.    87.2]\n",
      " [1027.4   65.6  452. ]\n",
      " [ 830.8  369.6  469.6]\n",
      " [ 984.6  333.6  316.8]\n",
      " [ 143.3  196.8   17.6]\n",
      " [1092.5   58.4   69.6]\n",
      " [ 993.7  221.6  427.2]\n",
      " [1290.4  336.   529.6]\n",
      " [ 638.4   15.2   72. ]\n",
      " [ 355.8  374.4  276. ]\n",
      " [ 854.5  168.8   76. ]\n",
      " [   3.2  316.8   69.6]\n",
      " [ 615.2  333.6  367.2]\n",
      " [  53.2  295.2  361.6]\n",
      " [ 401.8  204.   587.2]\n",
      " [1348.6  290.4  807.2]\n",
      " [  78.3  367.2  554.4]\n",
      " [1188.9  341.6  437.6]\n",
      " [1206.7   23.2  344. ]\n",
      " [ 899.1   28.    47.2]\n",
      " [ 364.9    0.    73.6]\n",
      " [ 854.9  137.6  143.2]\n",
      " [1099.7  304.   185.6]\n",
      " [ 909.1   20.8  169.6]\n",
      " [1293.6   84.8   51.2]\n",
      " [ 311.2  356.   284.8]\n",
      " [ 411.3    2.4  185.6]\n",
      " [ 881.3  283.2  604.8]\n",
      " [1091.5  332.   148. ]\n",
      " [  18.7   92.8   45.6]\n",
      " [ 921.4  178.4  252.8]\n",
      " [1214.4  350.4   40. ]\n",
      " [1038.8  135.2  209.6]\n",
      " [ 427.2  348.   404. ]\n",
      " [ 116.5  312.    74.4]\n",
      " [ 879.1  147.2  525.6]\n",
      " [ 971.   196.8  104.8]\n",
      " [ 899.1  186.4  113.6]\n",
      " [ 114.2  205.6  346.4]\n",
      " [  78.3   32.8  252.8]\n",
      " [  59.6    3.2  204.8]\n",
      " [ 748.5  167.2  379.2]\n",
      " [ 681.6   10.4  194.4]\n",
      " [ 261.6  262.4  188. ]\n",
      " [1083.8  274.4   42.4]\n",
      " [1322.7   32.8   68. ]\n",
      " [ 753.5   80.   140.8]\n",
      " [1259.9  391.2  334.4]\n",
      " [1080.2   40.8  188. ]\n",
      " [  33.2  224.8  331.2]\n",
      " [ 909.1   24.8  276.8]\n",
      " [1092.5  133.6  183.2]\n",
      " [1208.5  160.     2.4]\n",
      " [ 766.2   56.8  102.4]\n",
      " [ 467.3  236.8   67.2]\n",
      " [ 611.1   39.2   74.4]\n",
      " [ 202.5  314.4  360.8]\n",
      " [  24.6  239.2   75.2]\n",
      " [ 442.3   12.   240. ]\n",
      " [1301.3  111.2   29.6]\n",
      " [ 314.9  164.   146.4]\n",
      " [ 634.7   16.8  212.8]\n",
      " [ 408.1   79.2  285.6]\n",
      " [ 560.1  276.8   99.2]\n",
      " [ 503.7  324.8  505.6]\n",
      " [1154.8  170.4  240. ]\n",
      " [1130.2  241.6  162.4]\n",
      " [ 932.8  360.8  156.8]\n",
      " [ 958.7  236.    74.4]\n",
      " [1044.2  258.4  593.6]\n",
      " [1274.9   80.8  171.2]\n",
      " [ 550.6   67.2  389.6]\n",
      " [1259.    18.4  189.6]\n",
      " [ 196.1  213.6  280.8]\n",
      " [ 548.3  228.   113.6]\n",
      " [ 650.2  234.4  100.8]\n",
      " [  81.4  300.8  172.8]\n",
      " [ 499.6  114.4  253.6]\n",
      " [1033.8  126.4  399.2]\n",
      " [ 219.8  376.    68. ]\n",
      " [ 971.4  344.   270.4]\n",
      " [ 779.4  317.6  301.6]\n",
      " [1019.2   19.2  124.8]\n",
      " [1141.6  292.   578.4]\n",
      " [ 994.2   43.2  219.2]\n",
      " [ 986.4  351.2  217.6]\n",
      " [1318.1  338.4  409.6]\n",
      " [ 300.8   46.4  193.6]\n",
      " [ 588.8   45.6  250.4]\n",
      " [1056.1   68.8   69.6]\n",
      " [ 179.7  328.8   46.4]\n",
      " [1080.2  220.    88. ]\n",
      " [ 255.7   45.6  237.6]\n",
      " [1011.9   27.2  104.8]\n",
      " [ 941.4   67.2  211.2]\n",
      " [ 928.7  263.2  368. ]\n",
      " [ 167.9  308.8  524.8]\n",
      " [ 271.2   96.   344.8]\n",
      " [ 822.6   86.4  467.2]\n",
      " [1162.1  215.2   44. ]\n",
      " [ 596.5  342.4  231.2]\n",
      " [ 990.5  268.   472. ]\n",
      " [ 533.3  117.6   43.2]\n",
      " [1335.9  221.6   14.4]\n",
      " [ 308.5  292.8  912. ]\n",
      " [1106.6  392.   354.4]\n",
      " [ 805.4   74.4   51.2]\n",
      " [1002.4  392.    25.6]\n",
      " [ 347.6  213.6  178.4]\n",
      " [ 443.6   60.8   57.6]\n",
      " [ 389.9  286.4  394.4]\n",
      " [ 642.9  214.4  369.6]\n",
      " [ 243.4   16.   171.2]\n",
      " [ 841.3  168.   176. ]\n",
      " [  35.5  311.2  404.8]\n",
      " [  85.1   96.8  187.2]\n",
      " [ 784.9  144.8  245.6]\n",
      " [ 428.6   39.2   64.8]\n",
      " [ 173.8   29.6  110.4]\n",
      " [1037.4  301.6  256. ]\n",
      " [ 712.5   20.8   66.4]\n",
      " [ 172.9  322.4   95.2]\n",
      " [ 456.8   76.8   28.8]\n",
      " [ 396.8   94.4  207.2]\n",
      " [1332.7  226.4  345.6]\n",
      " [ 546.9  156.8   92.8]\n",
      " [ 857.2  144.8  204.8]\n",
      " [ 905.9  244.8  309.6]\n",
      " [ 475.9   45.6  275.2]\n",
      " [ 959.1  396.8  301.6]\n",
      " [ 125.1   12.8  165.6]\n",
      " [ 689.3  330.4  468. ]\n",
      " [ 869.5  229.6  145.6]\n",
      " [1195.3  230.4  127.2]\n",
      " [ 121.9  264.   154.4]\n",
      " [ 343.5   86.4   48. ]\n",
      " [ 796.7  180.   252. ]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df_ads)\n",
    "X = np.delete(X, [3], axis=1) # 删除标签\n",
    "y = np.array(df_ads.sales)\n",
    "print (\"张量X的阶:\",X.ndim)\n",
    "print (\"张量X的形状:\", X.shape)\n",
    "print (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "张量y的形状: (200, 1)\n"
     ]
    }
   ],
   "source": [
    "y = y.reshape(-1, 1) # 通过reshape函数把向量转换为矩阵，-1就是len(y),返回样本个数\n",
    "print (\"张量y的形状:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据集进行80%（训练集）和20%（验证集）的分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据压缩(归一化处理)\n",
    "def scaler(train, test):\n",
    "    min = train.min(axis=0)\n",
    "    max = train.max(axis=0)\n",
    "    gap = max - min\n",
    "    train -= min\n",
    "    train /= gap\n",
    "    test -= min\n",
    "    test /= gap\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于后面反归一化过程\n",
    "def min_max_gap(train):\n",
    "    min = train.min(axis=0)\n",
    "    max = train.max(axis=0)\n",
    "    gap = max - min\n",
    "    return min, max, gap\n",
    "\n",
    "y_min, y_max, y_gap = min_max_gap(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_original = X_train.copy() # 保留一份训练集数据副本，用于对要预测数据归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = scaler(X_train, X_test)\n",
    "y_train, y_test = scaler(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "张量X的形状: (160, 4)\n",
      "[[1.         0.39995488 0.1643002  0.42568162]\n",
      " [1.         0.72629521 0.83975659 0.34564644]\n",
      " [1.         0.22746071 0.31845842 0.35620053]\n",
      " [1.         0.66952402 0.05679513 0.30167106]\n",
      " [1.         0.81803143 0.98782961 0.38698329]\n",
      " [1.         0.35341003 0.27789047 0.09322779]\n",
      " [1.         0.24355215 0.40567951 0.28320141]\n",
      " [1.         0.44852996 0.83975659 0.40105541]\n",
      " [1.         0.44544703 0.09330629 0.07915567]\n",
      " [1.         0.71636965 0.86612576 0.294635  ]\n",
      " [1.         0.46597489 0.03245436 0.07651715]\n",
      " [1.         0.46319272 0.03651116 0.23131047]\n",
      " [1.         0.11594857 0.81135903 0.10202287]\n",
      " [1.         0.07353936 0.78498986 0.07915567]\n",
      " [1.         0.97706594 0.85192698 0.44766931]\n",
      " [1.         0.45770359 0.93509128 0.51627089]\n",
      " [1.         0.22204677 0.18255578 0.00527704]\n",
      " [1.         0.1898639  0.23732252 0.3764292 ]\n",
      " [1.         0.94871795 0.79716024 0.48812665]\n",
      " [1.         0.49808256 0.71602434 0.05013193]\n",
      " [1.         0.70682006 0.59229209 0.07915567]\n",
      " [1.         0.30716595 0.87626775 0.44151275]\n",
      " [1.         0.11662531 0.06896552 0.11873351]\n",
      " [1.         0.31506128 0.29411765 0.33948989]\n",
      " [1.         0.12106173 0.82758621 0.04837291]\n",
      " [1.         0.         0.22920892 0.0474934 ]\n",
      " [1.         0.19911272 0.2494929  0.15831135]\n",
      " [1.         0.43446876 0.86206897 0.25153914]\n",
      " [1.         0.07150914 0.21703854 0.2585752 ]\n",
      " [1.         0.66952402 0.04665314 0.18381706]\n",
      " [1.         0.0471464  0.75659229 0.18733509]\n",
      " [1.         0.6486202  0.71196755 0.66226913]\n",
      " [1.         0.39822543 0.57200811 0.12225154]\n",
      " [1.         0.07180991 0.51521298 0.37818821]\n",
      " [1.         0.57199789 0.79918864 0.3289358 ]\n",
      " [1.         0.29521017 0.         0.20140721]\n",
      " [1.         0.55252275 0.19675456 0.15215479]\n",
      " [1.         0.46251598 0.28803245 0.08707124]\n",
      " [1.         0.41597113 0.74239351 0.6939314 ]\n",
      " [1.         0.76329047 0.31440162 0.43623571]\n",
      " [1.         0.98804421 0.56795132 0.37730871]\n",
      " [1.         0.48988646 0.47870183 0.16534741]\n",
      " [1.         0.47484773 0.58823529 0.10817942]\n",
      " [1.         0.63974735 0.57606491 0.15743184]\n",
      " [1.         0.98052485 0.07707911 0.07211961]\n",
      " [1.         0.88540492 0.06490872 0.16886544]\n",
      " [1.         0.80637642 0.07707911 0.32189974]\n",
      " [1.         0.7205053  0.48073022 0.03254178]\n",
      " [1.         0.13339349 0.53549696 0.3060686 ]\n",
      " [1.         0.07759982 0.663286   0.16710642]\n",
      " [1.         0.66644109 0.9959432  0.52506596]\n",
      " [1.         0.7229115  0.47261663 0.50395778]\n",
      " [1.         0.50424844 0.831643   0.51187335]\n",
      " [1.         0.62846831 0.42190669 0.08091469]\n",
      " [1.         0.88472818 0.57809331 0.13720317]\n",
      " [1.         0.04992857 0.23935091 0.20316623]\n",
      " [1.         0.16896007 0.03448276 0.18557608]\n",
      " [1.         0.40709828 0.69574037 0.1064204 ]\n",
      " [1.         0.67877284 0.44624746 0.27528584]\n",
      " [1.         0.01090308 0.56389452 0.36147757]\n",
      " [1.         0.68426197 0.66125761 0.40193492]\n",
      " [1.         0.34378525 0.10953347 0.29991205]\n",
      " [1.         0.0837657  0.02434077 0.28759894]\n",
      " [1.         0.21482818 0.23123732 0.32102023]\n",
      " [1.         0.89909016 0.88235294 0.04133685]\n",
      " [1.         0.93330326 0.98580122 0.3649956 ]\n",
      " [1.         0.76705015 0.336714   0.22779244]\n",
      " [1.         0.75847808 0.16024341 0.4942832 ]\n",
      " [1.         0.21791112 0.73630832 1.        ]\n",
      " [1.         0.54530416 0.74036511 0.06244503]\n",
      " [1.         0.73313783 0.55578093 0.46701847]\n",
      " [1.         0.0530115  0.40162272 0.14687775]\n",
      " [1.         0.78825476 0.06288032 0.74318382]\n",
      " [1.         0.81284307 0.76470588 0.20140721]\n",
      " [1.         0.6544853  0.96146045 0.46262093]\n",
      " [1.         0.60448154 0.21298174 0.51099384]\n",
      " [1.         0.31333183 0.02231237 0.06244503]\n",
      " [1.         0.28430709 0.23326572 0.22515391]\n",
      " [1.         0.93262651 0.04056795 0.20580475]\n",
      " [1.         0.2370855  0.33874239 0.11081794]\n",
      " [1.         0.38281074 0.15010142 0.2005277 ]\n",
      " [1.         1.         0.73022312 0.88478452]\n",
      " [1.         0.54876306 0.4178499  0.41424802]\n",
      " [1.         0.13309271 0.51926978 0.17766051]\n",
      " [1.         0.66200466 0.46653144 0.12225154]\n",
      " [1.         0.0259418  0.74239351 0.39489886]\n",
      " [1.         0.05022934 0.43407708 0.44063325]\n",
      " [1.         0.56207234 0.13793103 0.10993843]\n",
      " [1.         0.73073163 0.67342799 0.51627089]\n",
      " [1.         0.24422889 0.21298174 0.05013193]\n",
      " [1.         0.94631175 0.27586207 0.32277924]\n",
      " [1.         0.80742913 0.14198783 0.07387863]\n",
      " [1.         0.62876908 0.34279919 0.15479332]\n",
      " [1.         0.31852019 0.02434077 0.26121372]\n",
      " [1.         0.17820889 0.10953347 0.2585752 ]\n",
      " [1.         0.24731183 0.53549696 0.19349164]\n",
      " [1.         0.74682307 0.06288032 0.11257696]\n",
      " [1.         0.80667719 0.8356998  0.16007036]\n",
      " [1.         0.58500639 0.45030426 0.27440633]\n",
      " [1.         0.0153395  0.03651116 0.00615655]\n",
      " [1.         0.13820588 0.79107505 0.39401935]\n",
      " [1.         0.0448154  0.07707911 0.27528584]\n",
      " [1.         0.24701105 0.55172414 0.13808267]\n",
      " [1.         0.2428754  0.70385396 0.46086192]\n",
      " [1.         0.61064742 0.93103448 0.51363237]\n",
      " [1.         0.74682307 0.0811359  0.4353562 ]\n",
      " [1.         0.00443642 0.60040568 0.08003518]\n",
      " [1.         0.85976389 0.53955375 0.04573439]\n",
      " [1.         0.59154824 0.67139959 0.33773087]\n",
      " [1.         0.49845853 0.02028398 0.21108179]\n",
      " [1.         0.77111061 0.64908722 0.64995602]\n",
      " [1.         0.27911873 0.72008114 0.43095866]\n",
      " [1.         0.36160614 0.96348884 0.44942832]\n",
      " [1.         0.03113016 0.31643002 0.43359719]\n",
      " [1.         0.9445823  0.19878296 0.18557608]\n",
      " [1.         0.73795022 0.67342799 0.39401935]\n",
      " [1.         0.69381156 0.1643002  0.22955145]\n",
      " [1.         0.85427476 0.42596349 0.26121372]\n",
      " [1.         0.15700429 0.22920892 0.15919085]\n",
      " [1.         0.5565832  0.84584178 0.02902375]\n",
      " [1.         0.80742913 0.3326572  0.19876869]\n",
      " [1.         0.42867885 0.10953347 0.27264732]\n",
      " [1.         0.06737349 0.70588235 0.5769569 ]\n",
      " [1.         0.99045041 0.55578093 0.01319261]\n",
      " [1.         0.36468907 0.81744422 0.5532102 ]\n",
      " [1.         0.61854275 0.4198783  0.19085312]\n",
      " [1.         0.24152192 0.9959432  0.39929639]\n",
      " [1.         0.15121438 0.94726166 0.07211961]\n",
      " [1.         0.59154824 0.18255578 0.05364996]\n",
      " [1.         0.7335138  0.10344828 0.23834653]\n",
      " [1.         0.58703662 0.30628803 0.01846966]\n",
      " [1.         0.71606888 0.49290061 0.11257696]\n",
      " [1.         0.66200466 0.06490872 0.04925242]\n",
      " [1.         0.0448154  0.92494929 0.60686016]\n",
      " [1.         0.89465373 0.39959432 0.        ]\n",
      " [1.         0.7276487  0.88438134 0.23658751]\n",
      " [1.         0.08000602 0.02636917 0.17941953]\n",
      " [1.         0.25347771 0.94320487 0.30079156]\n",
      " [1.         0.28806677 0.51115619 0.64291996]\n",
      " [1.         0.43649898 0.36713996 0.30167106]\n",
      " [1.         0.38694639 0.29208925 0.04485488]\n",
      " [1.         0.89330025 0.05273834 0.37554969]\n",
      " [1.         0.39717272 0.39148073 0.09938434]\n",
      " [1.         0.4693586  0.53752535 0.40369393]\n",
      " [1.         0.66711783 0.61460446 0.33773087]\n",
      " [1.         0.05233476 0.31845842 0.19349164]\n",
      " [1.         0.54462742 0.63488844 0.46262093]\n",
      " [1.         0.36160614 0.28397566 0.27616535]\n",
      " [1.         0.21994135 0.89655172 0.31046614]\n",
      " [1.         0.95623731 0.84584178 0.57959543]\n",
      " [1.         0.95864351 0.20892495 0.05364996]\n",
      " [1.         0.56823821 0.15212982 0.30694811]\n",
      " [1.         0.83713061 0.54361055 0.19876869]\n",
      " [1.         0.24731183 0.01014199 0.12752858]\n",
      " [1.         0.03075419 0.0020284  0.22251539]\n",
      " [1.         0.09369125 0.49290061 0.01671064]\n",
      " [1.         0.70712084 1.         0.3289358 ]\n",
      " [1.         0.3373186  0.59432049 0.07124011]\n",
      " [1.         0.37220844 0.34685598 0.33685136]\n",
      " [1.         0.31949771 0.14807302 0.06068602]]\n"
     ]
    }
   ],
   "source": [
    "x0_train = np.ones((len(X_train), 1))# 构造X_train长度的全1数组配合对Bias的点积\n",
    "X_train = np.append(x0_train, X_train, axis=1)#把X增加一系列的1\n",
    "x0_test = np.ones((len(X_test), 1))\n",
    "X_test = np.append(x0_test, X_test, axis=1)\n",
    "print (\"张量X的形状:\", X_train.shape)\n",
    "print (X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.2 多变量的损失函数和梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 手工定义一个MSE均方误差函数,W此时是一个向量\n",
    "def loss_function(X, y, W):\n",
    "    y_hat = X.dot(W.T)\n",
    "    loss = y_hat.reshape((len(y_hat), 1)) - y\n",
    "    cost = np.sum(loss**2) / (2*len(X))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义梯度下降函数\n",
    "def gradient_descent(X, y, W, alpha, iterations):\n",
    "    l_history = np.zeros(iterations)\n",
    "    W_history = np.zeros((iterations, len(W)))\n",
    "    for iter in range(iterations):\n",
    "        y_hat = X.dot(W)\n",
    "        loss = y_hat.reshape((len(y_hat), 1)) - y   # 中间过程, y_hat和y真值的差\n",
    "        derivative_W = X.T.dot(loss) / (2*len(X))   # 求出多项式的梯度向量\n",
    "        derivative_W = derivative_W.reshape(len(W))\n",
    "        W = W- alpha * derivative_W.reshape(len(W))\n",
    "        l_history[iter] = loss_function(X, y, W)\n",
    "        W_history[iter] = W\n",
    "    return l_history, W_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.3 构建一个线性回归函数模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前损失： 0.8039183733604858\n"
     ]
    }
   ],
   "source": [
    "# 首先确定参数的初始值\n",
    "iterations = 300\n",
    "alpha = 0.5\n",
    "weight = np.array([0.5, 1, 1, 1])\n",
    "print('当前损失：', loss_function(X_train, y_train, weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义线性回归模型\n",
    "def linear_regression(X, y, weight, alpha, iterations):\n",
    "    loss_history, weight_history = gradient_descent(X, y, \n",
    "                                                        weight, alpha, iterations)\n",
    "    print(\"训练最终稿损失：\", loss_history[-1])\n",
    "    y_pred = X.dot(weight_history[-1])\n",
    "    training_acc = 100 - np.mean(np.abs(y_pred-y))*100  # 计算准确率\n",
    "    print(\"线性回归训练准确率：{:.2f}%\".format(training_acc))\n",
    "    return loss_history, weight_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练最终稿损失： 0.0020534948072892627\n",
      "线性回归训练准确率：75.99%\n"
     ]
    }
   ],
   "source": [
    "# 调用刚才定义的线性回归模型\n",
    "loss_history, weight_history = linear_regression(X_train, y_train, \n",
    "                                                                weight, alpha, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "权重历史记录： [0.05592132 0.64217276 0.22460039 0.0889083 ]\n",
      "损失历史记录： 0.0020534948072892627\n"
     ]
    }
   ],
   "source": [
    "print(\"权重历史记录：\", weight_history[-1])\n",
    "print(\"损失历史记录：\", loss_history[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测商品的销售额： [7.94499196] 千元。\n"
     ]
    }
   ],
   "source": [
    "# 预测\n",
    "X_plan = [250, 50, 50]\n",
    "X_train, X_plan = scaler(X_train_original, X_plan)  # 归一化\n",
    "X_plan = np.append([1], X_plan)\n",
    "y_plan = np.dot(weight_history[-1], X_plan)\n",
    "y_value = y_plan*y_gap + y_min\n",
    "print(\"预测商品的销售额：\", y_value, \"千元。\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "694cdcaedaf049a0984f27e4a849c1af591c6b1d7a3cf6d6f220830adff0acba"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('Vuean_ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
