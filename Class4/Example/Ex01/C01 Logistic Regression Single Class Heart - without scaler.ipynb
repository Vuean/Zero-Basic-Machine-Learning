{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_heart = pd.read_csv('./dataset/heart.csv')\n",
    "df_heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    165\n",
       "0    138\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输出分类值，及各个类别数目\n",
    "df_heart.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x=df_heart.age[df_heart.target==1],\n",
    "                        y=df_heart.thalach[(df_heart.target==1)], c='red')\n",
    "plt.scatter(x=df_heart.age[df_heart.target==0],\n",
    "                        y=df_heart.thalach[(df_heart.target==0)], marker='^', c='blue')\n",
    "plt.legend([\"Disease\", \"No Disease\"])\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Heart Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ca</th>\n",
       "      <th>...</th>\n",
       "      <th>cp_1</th>\n",
       "      <th>cp_2</th>\n",
       "      <th>cp_3</th>\n",
       "      <th>thal_0</th>\n",
       "      <th>thal_1</th>\n",
       "      <th>thal_2</th>\n",
       "      <th>thal_3</th>\n",
       "      <th>slope_0</th>\n",
       "      <th>slope_1</th>\n",
       "      <th>slope_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  ca  ...  \\\n",
       "0   63    1       145   233    1        0      150      0      2.3   0  ...   \n",
       "1   37    1       130   250    0        1      187      0      3.5   0  ...   \n",
       "2   41    0       130   204    0        0      172      0      1.4   0  ...   \n",
       "3   56    1       120   236    0        1      178      0      0.8   0  ...   \n",
       "4   57    0       120   354    0        1      163      1      0.6   0  ...   \n",
       "\n",
       "   cp_1  cp_2  cp_3  thal_0  thal_1  thal_2  thal_3  slope_0  slope_1  slope_2  \n",
       "0     0     0     1       0       1       0       0        1        0        0  \n",
       "1     0     1     0       0       0       1       0        1        0        0  \n",
       "2     1     0     0       0       0       1       0        0        0        1  \n",
       "3     1     0     0       0       0       1       0        0        0        1  \n",
       "4     0     0     0       0       0       1       0        0        0        1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把3个文本型变量转换为哑变量\n",
    "a = pd.get_dummies(df_heart['cp'], prefix = 'cp')\n",
    "b = pd.get_dummies(df_heart['thal'], prefix = 'thal')\n",
    "c = pd.get_dummies(df_heart['slope'], prefix = 'slope')\n",
    "# 把哑变量添加进dataframe\n",
    "frames = [df_heart, a, b, c]\n",
    "df_heart = pd.concat(frames, axis = 1)\n",
    "df_heart = df_heart.drop(columns = ['cp', 'thal', 'slope'])\n",
    "df_heart.head() # 显示新的dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "张量X的形状： (303, 21)\n",
      "张量y的形状： (303, 1)\n"
     ]
    }
   ],
   "source": [
    "# 构建特征集\n",
    "X = df_heart.drop(['target'], axis=1)\n",
    "y = df_heart.target.values\n",
    "y = y.reshape(-1, 1)\n",
    "print(\"张量X的形状：\", X.shape)\n",
    "print(\"张量y的形状：\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不进行数据缩放，对比准确率\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先定义一个Sigmoid函数，输入Z，返回y'\n",
    "def sigmoid(z):\n",
    "    y_hat = 1 / (1+np.exp(-z))\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 然后定义损失函数\n",
    "def loss_function(X, y, w, b):\n",
    "    y_hat = sigmoid(np.dot(X, w) + b)\n",
    "    loss = -(y*np.log(y_hat) + (1-y)*np.log(1-y_hat))\n",
    "    cost = np.sum(loss) / X.shape[0]\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 然后构建梯度下降的函数\n",
    "def gradient_descent(X, y, w, b, alpha, iterations):\n",
    "    l_history = np.zeros(iterations)\n",
    "    w_history = np.zeros((iterations, w.shape[0], w.shape[1]))\n",
    "    b_history = np.zeros(iterations)\n",
    "    for i in range(iterations):\n",
    "        y_hat = sigmoid(np.dot(X, w)+b)\n",
    "        loss = -(y*np.log(y_hat) + (1-y)*np.log(1-y_hat))\n",
    "        derivative_w = np.dot(X.T, ((y_hat-y))) / X.shape[0]\n",
    "        derivative_b = np.sum(y_hat-y) / X.shape[0]\n",
    "        w = w - alpha * derivative_w\n",
    "        b = b - alpha * derivative_b\n",
    "        l_history[i] = loss_function(X, y, w, b)\n",
    "        print (\"轮次\", i+1 , \"当前轮训练集损失：\",l_history[i]) \n",
    "        w_history[i] = w # 梯度下降过程中权重的历史 请注意w_history和w的形状\n",
    "        b_history[i] = b # 梯度下降过程中偏置的历史\n",
    "    return l_history, w_history, b_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w, b):\n",
    "    z = np.dot(X, w) + b\n",
    "    y_hat = sigmoid(z)\n",
    "    y_pred = np.zeros((y_hat.shape[0], 1))\n",
    "    for i in range(y_hat.shape[0]):\n",
    "        if y_hat[i, 0] < 0.5:\n",
    "            y_pred[i, 0] = 0\n",
    "        else:\n",
    "            y_pred[i, 0] = 1\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X,y,w,b,lr,iter): # 定义逻辑回归模型\n",
    "    l_history,w_history,b_history = gradient_descent(X,y,w,b,lr,iter)#梯度下降\n",
    "    print(\"训练最终损失:\", l_history[-1]) # 打印最终损失\n",
    "    y_pred = predict(X,w_history[-1],b_history[-1]) # 进行预测\n",
    "    traning_acc = 100 - np.mean(np.abs(y_pred - y_train))*100 # 计算准确率\n",
    "    print(\"逻辑回归训练准确率: {:.2f}%\".format(traning_acc))  # 打印准确率\n",
    "    return l_history, w_history, b_history # 返回训练历史记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化参数\n",
    "dimension = X.shape[1] # 这里的维度 len(X)是矩阵的行的数，维度是列的数目\n",
    "weight = np.full((dimension,1),0.1) # 权重向量，向量一般是1D，但这里实际上创建了2D张量\n",
    "bias = 0 # 偏置值\n",
    "#初始化超参数\n",
    "alpha = 1 # 学习速率\n",
    "iterations = 500 # 迭代次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vuean\\AppData\\Local\\Temp/ipykernel_43384/3591997641.py:8: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(y*np.log(y_hat) + (1-y)*np.log(1-y_hat))\n",
      "C:\\Users\\Vuean\\AppData\\Local\\Temp/ipykernel_43384/3591997641.py:8: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -(y*np.log(y_hat) + (1-y)*np.log(1-y_hat))\n",
      "C:\\Users\\Vuean\\AppData\\Local\\Temp/ipykernel_43384/2920647579.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  y_hat = 1 / (1+np.exp(-z))\n",
      "C:\\Users\\Vuean\\AppData\\Local\\Temp/ipykernel_43384/1830858839.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(y*np.log(y_hat) + (1-y)*np.log(1-y_hat))\n",
      "C:\\Users\\Vuean\\AppData\\Local\\Temp/ipykernel_43384/1830858839.py:4: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -(y*np.log(y_hat) + (1-y)*np.log(1-y_hat))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "轮次 1 当前轮训练集损失： nan\n",
      "轮次 2 当前轮训练集损失： nan\n",
      "轮次 3 当前轮训练集损失： nan\n",
      "轮次 4 当前轮训练集损失： nan\n",
      "轮次 5 当前轮训练集损失： nan\n",
      "轮次 6 当前轮训练集损失： nan\n",
      "轮次 7 当前轮训练集损失： nan\n",
      "轮次 8 当前轮训练集损失： nan\n",
      "轮次 9 当前轮训练集损失： nan\n",
      "轮次 10 当前轮训练集损失： nan\n",
      "轮次 11 当前轮训练集损失： nan\n",
      "轮次 12 当前轮训练集损失： nan\n",
      "轮次 13 当前轮训练集损失： nan\n",
      "轮次 14 当前轮训练集损失： nan\n",
      "轮次 15 当前轮训练集损失： nan\n",
      "轮次 16 当前轮训练集损失： nan\n",
      "轮次 17 当前轮训练集损失： nan\n",
      "轮次 18 当前轮训练集损失： nan\n",
      "轮次 19 当前轮训练集损失： nan\n",
      "轮次 20 当前轮训练集损失： nan\n",
      "轮次 21 当前轮训练集损失： nan\n",
      "轮次 22 当前轮训练集损失： nan\n",
      "轮次 23 当前轮训练集损失： nan\n",
      "轮次 24 当前轮训练集损失： nan\n",
      "轮次 25 当前轮训练集损失： nan\n",
      "轮次 26 当前轮训练集损失： nan\n",
      "轮次 27 当前轮训练集损失： nan\n",
      "轮次 28 当前轮训练集损失： nan\n",
      "轮次 29 当前轮训练集损失： nan\n",
      "轮次 30 当前轮训练集损失： nan\n",
      "轮次 31 当前轮训练集损失： nan\n",
      "轮次 32 当前轮训练集损失： nan\n",
      "轮次 33 当前轮训练集损失： nan\n",
      "轮次 34 当前轮训练集损失： nan\n",
      "轮次 35 当前轮训练集损失： nan\n",
      "轮次 36 当前轮训练集损失： nan\n",
      "轮次 37 当前轮训练集损失： nan\n",
      "轮次 38 当前轮训练集损失： nan\n",
      "轮次 39 当前轮训练集损失： nan\n",
      "轮次 40 当前轮训练集损失： nan\n",
      "轮次 41 当前轮训练集损失： nan\n",
      "轮次 42 当前轮训练集损失： nan\n",
      "轮次 43 当前轮训练集损失： nan\n",
      "轮次 44 当前轮训练集损失： nan\n",
      "轮次 45 当前轮训练集损失： nan\n",
      "轮次 46 当前轮训练集损失： nan\n",
      "轮次 47 当前轮训练集损失： nan\n",
      "轮次 48 当前轮训练集损失： nan\n",
      "轮次 49 当前轮训练集损失： nan\n",
      "轮次 50 当前轮训练集损失： nan\n",
      "轮次 51 当前轮训练集损失： nan\n",
      "轮次 52 当前轮训练集损失： nan\n",
      "轮次 53 当前轮训练集损失： nan\n",
      "轮次 54 当前轮训练集损失： nan\n",
      "轮次 55 当前轮训练集损失： nan\n",
      "轮次 56 当前轮训练集损失： nan\n",
      "轮次 57 当前轮训练集损失： nan\n",
      "轮次 58 当前轮训练集损失： nan\n",
      "轮次 59 当前轮训练集损失： nan\n",
      "轮次 60 当前轮训练集损失： nan\n",
      "轮次 61 当前轮训练集损失： nan\n",
      "轮次 62 当前轮训练集损失： nan\n",
      "轮次 63 当前轮训练集损失： nan\n",
      "轮次 64 当前轮训练集损失： nan\n",
      "轮次 65 当前轮训练集损失： nan\n",
      "轮次 66 当前轮训练集损失： nan\n",
      "轮次 67 当前轮训练集损失： nan\n",
      "轮次 68 当前轮训练集损失： nan\n",
      "轮次 69 当前轮训练集损失： nan\n",
      "轮次 70 当前轮训练集损失： nan\n",
      "轮次 71 当前轮训练集损失： nan\n",
      "轮次 72 当前轮训练集损失： nan\n",
      "轮次 73 当前轮训练集损失： nan\n",
      "轮次 74 当前轮训练集损失： nan\n",
      "轮次 75 当前轮训练集损失： nan\n",
      "轮次 76 当前轮训练集损失： nan\n",
      "轮次 77 当前轮训练集损失： nan\n",
      "轮次 78 当前轮训练集损失： nan\n",
      "轮次 79 当前轮训练集损失： nan\n",
      "轮次 80 当前轮训练集损失： nan\n",
      "轮次 81 当前轮训练集损失： nan\n",
      "轮次 82 当前轮训练集损失： nan\n",
      "轮次 83 当前轮训练集损失： nan\n",
      "轮次 84 当前轮训练集损失： nan\n",
      "轮次 85 当前轮训练集损失： nan\n",
      "轮次 86 当前轮训练集损失： nan\n",
      "轮次 87 当前轮训练集损失： nan\n",
      "轮次 88 当前轮训练集损失： nan\n",
      "轮次 89 当前轮训练集损失： nan\n",
      "轮次 90 当前轮训练集损失： nan\n",
      "轮次 91 当前轮训练集损失： nan\n",
      "轮次 92 当前轮训练集损失： nan\n",
      "轮次 93 当前轮训练集损失： nan\n",
      "轮次 94 当前轮训练集损失： nan\n",
      "轮次 95 当前轮训练集损失： nan\n",
      "轮次 96 当前轮训练集损失： nan\n",
      "轮次 97 当前轮训练集损失： nan\n",
      "轮次 98 当前轮训练集损失： nan\n",
      "轮次 99 当前轮训练集损失： nan\n",
      "轮次 100 当前轮训练集损失： nan\n",
      "轮次 101 当前轮训练集损失： nan\n",
      "轮次 102 当前轮训练集损失： nan\n",
      "轮次 103 当前轮训练集损失： nan\n",
      "轮次 104 当前轮训练集损失： nan\n",
      "轮次 105 当前轮训练集损失： nan\n",
      "轮次 106 当前轮训练集损失： nan\n",
      "轮次 107 当前轮训练集损失： nan\n",
      "轮次 108 当前轮训练集损失： nan\n",
      "轮次 109 当前轮训练集损失： nan\n",
      "轮次 110 当前轮训练集损失： nan\n",
      "轮次 111 当前轮训练集损失： nan\n",
      "轮次 112 当前轮训练集损失： nan\n",
      "轮次 113 当前轮训练集损失： nan\n",
      "轮次 114 当前轮训练集损失： nan\n",
      "轮次 115 当前轮训练集损失： nan\n",
      "轮次 116 当前轮训练集损失： nan\n",
      "轮次 117 当前轮训练集损失： nan\n",
      "轮次 118 当前轮训练集损失： nan\n",
      "轮次 119 当前轮训练集损失： nan\n",
      "轮次 120 当前轮训练集损失： nan\n",
      "轮次 121 当前轮训练集损失： nan\n",
      "轮次 122 当前轮训练集损失： nan\n",
      "轮次 123 当前轮训练集损失： nan\n",
      "轮次 124 当前轮训练集损失： nan\n",
      "轮次 125 当前轮训练集损失： nan\n",
      "轮次 126 当前轮训练集损失： nan\n",
      "轮次 127 当前轮训练集损失： nan\n",
      "轮次 128 当前轮训练集损失： nan\n",
      "轮次 129 当前轮训练集损失： nan\n",
      "轮次 130 当前轮训练集损失： nan\n",
      "轮次 131 当前轮训练集损失： nan\n",
      "轮次 132 当前轮训练集损失： nan\n",
      "轮次 133 当前轮训练集损失： nan\n",
      "轮次 134 当前轮训练集损失： nan\n",
      "轮次 135 当前轮训练集损失： nan\n",
      "轮次 136 当前轮训练集损失： nan\n",
      "轮次 137 当前轮训练集损失： nan\n",
      "轮次 138 当前轮训练集损失： nan\n",
      "轮次 139 当前轮训练集损失： nan\n",
      "轮次 140 当前轮训练集损失： nan\n",
      "轮次 141 当前轮训练集损失： nan\n",
      "轮次 142 当前轮训练集损失： nan\n",
      "轮次 143 当前轮训练集损失： nan\n",
      "轮次 144 当前轮训练集损失： nan\n",
      "轮次 145 当前轮训练集损失： nan\n",
      "轮次 146 当前轮训练集损失： nan\n",
      "轮次 147 当前轮训练集损失： nan\n",
      "轮次 148 当前轮训练集损失： nan\n",
      "轮次 149 当前轮训练集损失： nan\n",
      "轮次 150 当前轮训练集损失： nan\n",
      "轮次 151 当前轮训练集损失： nan\n",
      "轮次 152 当前轮训练集损失： nan\n",
      "轮次 153 当前轮训练集损失： nan\n",
      "轮次 154 当前轮训练集损失： nan\n",
      "轮次 155 当前轮训练集损失： nan\n",
      "轮次 156 当前轮训练集损失： nan\n",
      "轮次 157 当前轮训练集损失： nan\n",
      "轮次 158 当前轮训练集损失： nan\n",
      "轮次 159 当前轮训练集损失： nan\n",
      "轮次 160 当前轮训练集损失： nan\n",
      "轮次 161 当前轮训练集损失： nan\n",
      "轮次 162 当前轮训练集损失： nan\n",
      "轮次 163 当前轮训练集损失： nan\n",
      "轮次 164 当前轮训练集损失： nan\n",
      "轮次 165 当前轮训练集损失： nan\n",
      "轮次 166 当前轮训练集损失： nan\n",
      "轮次 167 当前轮训练集损失： nan\n",
      "轮次 168 当前轮训练集损失： nan\n",
      "轮次 169 当前轮训练集损失： nan\n",
      "轮次 170 当前轮训练集损失： nan\n",
      "轮次 171 当前轮训练集损失： nan\n",
      "轮次 172 当前轮训练集损失： nan\n",
      "轮次 173 当前轮训练集损失： nan\n",
      "轮次 174 当前轮训练集损失： nan\n",
      "轮次 175 当前轮训练集损失： nan\n",
      "轮次 176 当前轮训练集损失： nan\n",
      "轮次 177 当前轮训练集损失： nan\n",
      "轮次 178 当前轮训练集损失： nan\n",
      "轮次 179 当前轮训练集损失： nan\n",
      "轮次 180 当前轮训练集损失： nan\n",
      "轮次 181 当前轮训练集损失： nan\n",
      "轮次 182 当前轮训练集损失： nan\n",
      "轮次 183 当前轮训练集损失： nan\n",
      "轮次 184 当前轮训练集损失： nan\n",
      "轮次 185 当前轮训练集损失： nan\n",
      "轮次 186 当前轮训练集损失： nan\n",
      "轮次 187 当前轮训练集损失： nan\n",
      "轮次 188 当前轮训练集损失： nan\n",
      "轮次 189 当前轮训练集损失： nan\n",
      "轮次 190 当前轮训练集损失： nan\n",
      "轮次 191 当前轮训练集损失： nan\n",
      "轮次 192 当前轮训练集损失： nan\n",
      "轮次 193 当前轮训练集损失： nan\n",
      "轮次 194 当前轮训练集损失： nan\n",
      "轮次 195 当前轮训练集损失： nan\n",
      "轮次 196 当前轮训练集损失： nan\n",
      "轮次 197 当前轮训练集损失： nan\n",
      "轮次 198 当前轮训练集损失： nan\n",
      "轮次 199 当前轮训练集损失： nan\n",
      "轮次 200 当前轮训练集损失： nan\n",
      "轮次 201 当前轮训练集损失： nan\n",
      "轮次 202 当前轮训练集损失： nan\n",
      "轮次 203 当前轮训练集损失： nan\n",
      "轮次 204 当前轮训练集损失： nan\n",
      "轮次 205 当前轮训练集损失： nan\n",
      "轮次 206 当前轮训练集损失： nan\n",
      "轮次 207 当前轮训练集损失： nan\n",
      "轮次 208 当前轮训练集损失： nan\n",
      "轮次 209 当前轮训练集损失： nan\n",
      "轮次 210 当前轮训练集损失： nan\n",
      "轮次 211 当前轮训练集损失： nan\n",
      "轮次 212 当前轮训练集损失： nan\n",
      "轮次 213 当前轮训练集损失： nan\n",
      "轮次 214 当前轮训练集损失： nan\n",
      "轮次 215 当前轮训练集损失： nan\n",
      "轮次 216 当前轮训练集损失： nan\n",
      "轮次 217 当前轮训练集损失： nan\n",
      "轮次 218 当前轮训练集损失： nan\n",
      "轮次 219 当前轮训练集损失： nan\n",
      "轮次 220 当前轮训练集损失： nan\n",
      "轮次 221 当前轮训练集损失： nan\n",
      "轮次 222 当前轮训练集损失： nan\n",
      "轮次 223 当前轮训练集损失： nan\n",
      "轮次 224 当前轮训练集损失： nan\n",
      "轮次 225 当前轮训练集损失： nan\n",
      "轮次 226 当前轮训练集损失： nan\n",
      "轮次 227 当前轮训练集损失： nan\n",
      "轮次 228 当前轮训练集损失： nan\n",
      "轮次 229 当前轮训练集损失： nan\n",
      "轮次 230 当前轮训练集损失： nan\n",
      "轮次 231 当前轮训练集损失： nan\n",
      "轮次 232 当前轮训练集损失： nan\n",
      "轮次 233 当前轮训练集损失： nan\n",
      "轮次 234 当前轮训练集损失： nan\n",
      "轮次 235 当前轮训练集损失： nan\n",
      "轮次 236 当前轮训练集损失： nan\n",
      "轮次 237 当前轮训练集损失： nan\n",
      "轮次 238 当前轮训练集损失： nan\n",
      "轮次 239 当前轮训练集损失： nan\n",
      "轮次 240 当前轮训练集损失： nan\n",
      "轮次 241 当前轮训练集损失： nan\n",
      "轮次 242 当前轮训练集损失： nan\n",
      "轮次 243 当前轮训练集损失： nan\n",
      "轮次 244 当前轮训练集损失： nan\n",
      "轮次 245 当前轮训练集损失： nan\n",
      "轮次 246 当前轮训练集损失： nan\n",
      "轮次 247 当前轮训练集损失： nan\n",
      "轮次 248 当前轮训练集损失： nan\n",
      "轮次 249 当前轮训练集损失： nan\n",
      "轮次 250 当前轮训练集损失： nan\n",
      "轮次 251 当前轮训练集损失： nan\n",
      "轮次 252 当前轮训练集损失： nan\n",
      "轮次 253 当前轮训练集损失： nan\n",
      "轮次 254 当前轮训练集损失： nan\n",
      "轮次 255 当前轮训练集损失： nan\n",
      "轮次 256 当前轮训练集损失： nan\n",
      "轮次 257 当前轮训练集损失： nan\n",
      "轮次 258 当前轮训练集损失： nan\n",
      "轮次 259 当前轮训练集损失： nan\n",
      "轮次 260 当前轮训练集损失： nan\n",
      "轮次 261 当前轮训练集损失： nan\n",
      "轮次 262 当前轮训练集损失： nan\n",
      "轮次 263 当前轮训练集损失： nan\n",
      "轮次 264 当前轮训练集损失： nan\n",
      "轮次 265 当前轮训练集损失： nan\n",
      "轮次 266 当前轮训练集损失： nan\n",
      "轮次 267 当前轮训练集损失： nan\n",
      "轮次 268 当前轮训练集损失： nan\n",
      "轮次 269 当前轮训练集损失： nan\n",
      "轮次 270 当前轮训练集损失： nan\n",
      "轮次 271 当前轮训练集损失： nan\n",
      "轮次 272 当前轮训练集损失： nan\n",
      "轮次 273 当前轮训练集损失： nan\n",
      "轮次 274 当前轮训练集损失： nan\n",
      "轮次 275 当前轮训练集损失： nan\n",
      "轮次 276 当前轮训练集损失： nan\n",
      "轮次 277 当前轮训练集损失： nan\n",
      "轮次 278 当前轮训练集损失： nan\n",
      "轮次 279 当前轮训练集损失： nan\n",
      "轮次 280 当前轮训练集损失： nan\n",
      "轮次 281 当前轮训练集损失： nan\n",
      "轮次 282 当前轮训练集损失： nan\n",
      "轮次 283 当前轮训练集损失： nan\n",
      "轮次 284 当前轮训练集损失： nan\n",
      "轮次 285 当前轮训练集损失： nan\n",
      "轮次 286 当前轮训练集损失： nan\n",
      "轮次 287 当前轮训练集损失： nan\n",
      "轮次 288 当前轮训练集损失： nan\n",
      "轮次 289 当前轮训练集损失： nan\n",
      "轮次 290 当前轮训练集损失： nan\n",
      "轮次 291 当前轮训练集损失： nan\n",
      "轮次 292 当前轮训练集损失： nan\n",
      "轮次 293 当前轮训练集损失： nan\n",
      "轮次 294 当前轮训练集损失： nan\n",
      "轮次 295 当前轮训练集损失： nan\n",
      "轮次 296 当前轮训练集损失： nan\n",
      "轮次 297 当前轮训练集损失： nan\n",
      "轮次 298 当前轮训练集损失： nan\n",
      "轮次 299 当前轮训练集损失： nan\n",
      "轮次 300 当前轮训练集损失： nan\n",
      "轮次 301 当前轮训练集损失： nan\n",
      "轮次 302 当前轮训练集损失： nan\n",
      "轮次 303 当前轮训练集损失： nan\n",
      "轮次 304 当前轮训练集损失： nan\n",
      "轮次 305 当前轮训练集损失： nan\n",
      "轮次 306 当前轮训练集损失： nan\n",
      "轮次 307 当前轮训练集损失： nan\n",
      "轮次 308 当前轮训练集损失： nan\n",
      "轮次 309 当前轮训练集损失： nan\n",
      "轮次 310 当前轮训练集损失： nan\n",
      "轮次 311 当前轮训练集损失： nan\n",
      "轮次 312 当前轮训练集损失： nan\n",
      "轮次 313 当前轮训练集损失： nan\n",
      "轮次 314 当前轮训练集损失： nan\n",
      "轮次 315 当前轮训练集损失： nan\n",
      "轮次 316 当前轮训练集损失： nan\n",
      "轮次 317 当前轮训练集损失： nan\n",
      "轮次 318 当前轮训练集损失： nan\n",
      "轮次 319 当前轮训练集损失： nan\n",
      "轮次 320 当前轮训练集损失： nan\n",
      "轮次 321 当前轮训练集损失： nan\n",
      "轮次 322 当前轮训练集损失： nan\n",
      "轮次 323 当前轮训练集损失： nan\n",
      "轮次 324 当前轮训练集损失： nan\n",
      "轮次 325 当前轮训练集损失： nan\n",
      "轮次 326 当前轮训练集损失： nan\n",
      "轮次 327 当前轮训练集损失： nan\n",
      "轮次 328 当前轮训练集损失： nan\n",
      "轮次 329 当前轮训练集损失： nan\n",
      "轮次 330 当前轮训练集损失： nan\n",
      "轮次 331 当前轮训练集损失： nan\n",
      "轮次 332 当前轮训练集损失： nan\n",
      "轮次 333 当前轮训练集损失： nan\n",
      "轮次 334 当前轮训练集损失： nan\n",
      "轮次 335 当前轮训练集损失： nan\n",
      "轮次 336 当前轮训练集损失： nan\n",
      "轮次 337 当前轮训练集损失： nan\n",
      "轮次 338 当前轮训练集损失： nan\n",
      "轮次 339 当前轮训练集损失： nan\n",
      "轮次 340 当前轮训练集损失： nan\n",
      "轮次 341 当前轮训练集损失： nan\n",
      "轮次 342 当前轮训练集损失： nan\n",
      "轮次 343 当前轮训练集损失： nan\n",
      "轮次 344 当前轮训练集损失： nan\n",
      "轮次 345 当前轮训练集损失： nan\n",
      "轮次 346 当前轮训练集损失： nan\n",
      "轮次 347 当前轮训练集损失： nan\n",
      "轮次 348 当前轮训练集损失： nan\n",
      "轮次 349 当前轮训练集损失： nan\n",
      "轮次 350 当前轮训练集损失： nan\n",
      "轮次 351 当前轮训练集损失： nan\n",
      "轮次 352 当前轮训练集损失： nan\n",
      "轮次 353 当前轮训练集损失： nan\n",
      "轮次 354 当前轮训练集损失： nan\n",
      "轮次 355 当前轮训练集损失： nan\n",
      "轮次 356 当前轮训练集损失： nan\n",
      "轮次 357 当前轮训练集损失： nan\n",
      "轮次 358 当前轮训练集损失： nan\n",
      "轮次 359 当前轮训练集损失： nan\n",
      "轮次 360 当前轮训练集损失： nan\n",
      "轮次 361 当前轮训练集损失： nan\n",
      "轮次 362 当前轮训练集损失： nan\n",
      "轮次 363 当前轮训练集损失： nan\n",
      "轮次 364 当前轮训练集损失： nan\n",
      "轮次 365 当前轮训练集损失： nan\n",
      "轮次 366 当前轮训练集损失： nan\n",
      "轮次 367 当前轮训练集损失： nan\n",
      "轮次 368 当前轮训练集损失： nan\n",
      "轮次 369 当前轮训练集损失： nan\n",
      "轮次 370 当前轮训练集损失： nan\n",
      "轮次 371 当前轮训练集损失： nan\n",
      "轮次 372 当前轮训练集损失： nan\n",
      "轮次 373 当前轮训练集损失： nan\n",
      "轮次 374 当前轮训练集损失： nan\n",
      "轮次 375 当前轮训练集损失： nan\n",
      "轮次 376 当前轮训练集损失： nan\n",
      "轮次 377 当前轮训练集损失： nan\n",
      "轮次 378 当前轮训练集损失： nan\n",
      "轮次 379 当前轮训练集损失： nan\n",
      "轮次 380 当前轮训练集损失： nan\n",
      "轮次 381 当前轮训练集损失： nan\n",
      "轮次 382 当前轮训练集损失： nan\n",
      "轮次 383 当前轮训练集损失： nan\n",
      "轮次 384 当前轮训练集损失： nan\n",
      "轮次 385 当前轮训练集损失： nan\n",
      "轮次 386 当前轮训练集损失： nan\n",
      "轮次 387 当前轮训练集损失： nan\n",
      "轮次 388 当前轮训练集损失： nan\n",
      "轮次 389 当前轮训练集损失： nan\n",
      "轮次 390 当前轮训练集损失： nan\n",
      "轮次 391 当前轮训练集损失： nan\n",
      "轮次 392 当前轮训练集损失： nan\n",
      "轮次 393 当前轮训练集损失： nan\n",
      "轮次 394 当前轮训练集损失： nan\n",
      "轮次 395 当前轮训练集损失： nan\n",
      "轮次 396 当前轮训练集损失： nan\n",
      "轮次 397 当前轮训练集损失： nan\n",
      "轮次 398 当前轮训练集损失： nan\n",
      "轮次 399 当前轮训练集损失： nan\n",
      "轮次 400 当前轮训练集损失： nan\n",
      "轮次 401 当前轮训练集损失： nan\n",
      "轮次 402 当前轮训练集损失： nan\n",
      "轮次 403 当前轮训练集损失： nan\n",
      "轮次 404 当前轮训练集损失： nan\n",
      "轮次 405 当前轮训练集损失： nan\n",
      "轮次 406 当前轮训练集损失： nan\n",
      "轮次 407 当前轮训练集损失： nan\n",
      "轮次 408 当前轮训练集损失： nan\n",
      "轮次 409 当前轮训练集损失： nan\n",
      "轮次 410 当前轮训练集损失： nan\n",
      "轮次 411 当前轮训练集损失： nan\n",
      "轮次 412 当前轮训练集损失： nan\n",
      "轮次 413 当前轮训练集损失： nan\n",
      "轮次 414 当前轮训练集损失： nan\n",
      "轮次 415 当前轮训练集损失： nan\n",
      "轮次 416 当前轮训练集损失： nan\n",
      "轮次 417 当前轮训练集损失： nan\n",
      "轮次 418 当前轮训练集损失： nan\n",
      "轮次 419 当前轮训练集损失： nan\n",
      "轮次 420 当前轮训练集损失： nan\n",
      "轮次 421 当前轮训练集损失： nan\n",
      "轮次 422 当前轮训练集损失： nan\n",
      "轮次 423 当前轮训练集损失： nan\n",
      "轮次 424 当前轮训练集损失： nan\n",
      "轮次 425 当前轮训练集损失： nan\n",
      "轮次 426 当前轮训练集损失： nan\n",
      "轮次 427 当前轮训练集损失： nan\n",
      "轮次 428 当前轮训练集损失： nan\n",
      "轮次 429 当前轮训练集损失： nan\n",
      "轮次 430 当前轮训练集损失： nan\n",
      "轮次 431 当前轮训练集损失： nan\n",
      "轮次 432 当前轮训练集损失： nan\n",
      "轮次 433 当前轮训练集损失： nan\n",
      "轮次 434 当前轮训练集损失： nan\n",
      "轮次 435 当前轮训练集损失： nan\n",
      "轮次 436 当前轮训练集损失： nan\n",
      "轮次 437 当前轮训练集损失： nan\n",
      "轮次 438 当前轮训练集损失： nan\n",
      "轮次 439 当前轮训练集损失： nan\n",
      "轮次 440 当前轮训练集损失： nan\n",
      "轮次 441 当前轮训练集损失： nan\n",
      "轮次 442 当前轮训练集损失： nan\n",
      "轮次 443 当前轮训练集损失： nan\n",
      "轮次 444 当前轮训练集损失： nan\n",
      "轮次 445 当前轮训练集损失： nan\n",
      "轮次 446 当前轮训练集损失： nan\n",
      "轮次 447 当前轮训练集损失： nan\n",
      "轮次 448 当前轮训练集损失： nan\n",
      "轮次 449 当前轮训练集损失： nan\n",
      "轮次 450 当前轮训练集损失： nan\n",
      "轮次 451 当前轮训练集损失： nan\n",
      "轮次 452 当前轮训练集损失： nan\n",
      "轮次 453 当前轮训练集损失： nan\n",
      "轮次 454 当前轮训练集损失： nan\n",
      "轮次 455 当前轮训练集损失： nan\n",
      "轮次 456 当前轮训练集损失： nan\n",
      "轮次 457 当前轮训练集损失： nan\n",
      "轮次 458 当前轮训练集损失： nan\n",
      "轮次 459 当前轮训练集损失： nan\n",
      "轮次 460 当前轮训练集损失： nan\n",
      "轮次 461 当前轮训练集损失： nan\n",
      "轮次 462 当前轮训练集损失： nan\n",
      "轮次 463 当前轮训练集损失： nan\n",
      "轮次 464 当前轮训练集损失： nan\n",
      "轮次 465 当前轮训练集损失： nan\n",
      "轮次 466 当前轮训练集损失： nan\n",
      "轮次 467 当前轮训练集损失： nan\n",
      "轮次 468 当前轮训练集损失： nan\n",
      "轮次 469 当前轮训练集损失： nan\n",
      "轮次 470 当前轮训练集损失： nan\n",
      "轮次 471 当前轮训练集损失： nan\n",
      "轮次 472 当前轮训练集损失： nan\n",
      "轮次 473 当前轮训练集损失： nan\n",
      "轮次 474 当前轮训练集损失： nan\n",
      "轮次 475 当前轮训练集损失： nan\n",
      "轮次 476 当前轮训练集损失： nan\n",
      "轮次 477 当前轮训练集损失： nan\n",
      "轮次 478 当前轮训练集损失： nan\n",
      "轮次 479 当前轮训练集损失： nan\n",
      "轮次 480 当前轮训练集损失： nan\n",
      "轮次 481 当前轮训练集损失： nan\n",
      "轮次 482 当前轮训练集损失： nan\n",
      "轮次 483 当前轮训练集损失： nan\n",
      "轮次 484 当前轮训练集损失： nan\n",
      "轮次 485 当前轮训练集损失： nan\n",
      "轮次 486 当前轮训练集损失： nan\n",
      "轮次 487 当前轮训练集损失： nan\n",
      "轮次 488 当前轮训练集损失： nan\n",
      "轮次 489 当前轮训练集损失： nan\n",
      "轮次 490 当前轮训练集损失： nan\n",
      "轮次 491 当前轮训练集损失： nan\n",
      "轮次 492 当前轮训练集损失： nan\n",
      "轮次 493 当前轮训练集损失： nan\n",
      "轮次 494 当前轮训练集损失： nan\n",
      "轮次 495 当前轮训练集损失： nan\n",
      "轮次 496 当前轮训练集损失： nan\n",
      "轮次 497 当前轮训练集损失： nan\n",
      "轮次 498 当前轮训练集损失： nan\n",
      "轮次 499 当前轮训练集损失： nan\n",
      "轮次 500 当前轮训练集损失： nan\n",
      "训练最终损失: nan\n",
      "逻辑回归训练准确率: 57.44%\n"
     ]
    }
   ],
   "source": [
    "# 用逻辑回归函数训练机器\n",
    "loss_history, weight_history, bias_history =  \\\n",
    "            logistic_regression(X_train,y_train,weight,bias,alpha,iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "逻辑回归测试准确率: 60.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vuean\\AppData\\Local\\Temp/ipykernel_43384/2920647579.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  y_hat = 1 / (1+np.exp(-z))\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(X_test,weight_history[-1],bias_history[-1]) # 预测测试集\n",
    "testing_acc = 100 - np.mean(np.abs(y_pred - y_test))*100 # 计算准确率\n",
    "print(\"逻辑回归测试准确率: {:.2f}%\".format(testing_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "逻辑回归预测分类值: [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vuean\\AppData\\Local\\Temp/ipykernel_43384/2920647579.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  y_hat = 1 / (1+np.exp(-z))\n"
     ]
    }
   ],
   "source": [
    "print (\"逻辑回归预测分类值:\",predict(X_test,weight_history[-1],bias_history[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vuean\\AppData\\Local\\Temp/ipykernel_43384/2920647579.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  y_hat = 1 / (1+np.exp(-z))\n",
      "C:\\Users\\Vuean\\AppData\\Local\\Temp/ipykernel_43384/1830858839.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(y*np.log(y_hat) + (1-y)*np.log(1-y_hat))\n",
      "C:\\Users\\Vuean\\AppData\\Local\\Temp/ipykernel_43384/1830858839.py:4: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -(y*np.log(y_hat) + (1-y)*np.log(1-y_hat))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_history_test = np.zeros(iterations) # 初始化历史损失\n",
    "for i in range(iterations): #求训练过程中不同参数带来的测试集损失\n",
    "    loss_history_test[i] = loss_function(X_test,y_test,\n",
    "                                         weight_history[i],bias_history[i])\n",
    "index = np.arange(0,iterations,1)\n",
    "plt.plot(index, loss_history,c='blue',linestyle='solid')\n",
    "plt.plot(index, loss_history_test,c='red',linestyle='dashed')\n",
    "plt.legend([\"Training Loss\", \"Test Loss\"])\n",
    "plt.xlabel(\"Number of Iteration\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.show() # 同时显示显示训练集和测试集损失曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SK-learn逻辑回归测试准确率86.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\Vuean_ML\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\Anaconda3\\envs\\Vuean_ML\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression #导入逻辑回归模型\n",
    "lr = LogisticRegression() # lr,就代表是逻辑回归模型\n",
    "lr.fit(X_train,y_train) # fit,就相当于是梯度下降\n",
    "print(\"SK-learn逻辑回归测试准确率{:.2f}%\".format(lr.score(X_test,y_test)*100))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "694cdcaedaf049a0984f27e4a849c1af591c6b1d7a3cf6d6f220830adff0acba"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('Vuean_ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
