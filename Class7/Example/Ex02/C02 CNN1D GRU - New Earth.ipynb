{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 7.8.1 时序数据的导入和处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LABEL   FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6  FLUX.7  \\\n",
      "0      2    93.85    83.81    20.10   -26.98   -39.56  -124.71 -135.18   \n",
      "1      2   -38.88   -33.83   -58.54   -40.09   -79.31   -72.81  -86.55   \n",
      "2      2   532.64   535.92   513.73   496.92   456.45   466.00  464.50   \n",
      "3      2   326.52   347.39   302.35   298.13   317.74   312.70  322.33   \n",
      "4      2 -1107.21 -1112.59 -1118.95 -1095.10 -1057.55 -1034.48 -998.34   \n",
      "\n",
      "    FLUX.8  FLUX.9  ...  FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
      "0   -96.27  -79.89  ...     -78.07    -102.15    -102.15      25.13   \n",
      "1   -85.33  -83.97  ...      -3.28     -32.21     -32.21     -24.89   \n",
      "2   486.39  436.56  ...     -71.69      13.31      13.31     -29.89   \n",
      "3   311.31  312.42  ...       5.71      -3.73      -3.73      30.05   \n",
      "4 -1022.71 -989.57  ...    -594.37    -401.66    -401.66    -357.24   \n",
      "\n",
      "   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
      "0      48.57      92.54      39.32      61.42       5.08     -39.54  \n",
      "1      -4.86       0.76     -11.70       6.46      16.00      19.93  \n",
      "2     -20.88       5.06     -11.80     -28.91     -70.02     -96.67  \n",
      "3      20.03     -12.67      -8.77     -17.31     -17.35      13.98  \n",
      "4    -443.76    -438.54    -399.71    -384.65    -411.79    -510.54  \n",
      "\n",
      "[5 rows x 3198 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5087 entries, 0 to 5086\n",
      "Columns: 3198 entries, LABEL to FLUX.3197\n",
      "dtypes: float64(3197), int64(1)\n",
      "memory usage: 124.1 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 首先把数据从文件中读入Dataframe：\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_train = pd.read_csv('./dataset/exoTrain.csv')\n",
    "df_test = pd.read_csv('./dataset/exoTest.csv')\n",
    "print(df_train.head()) # 输入头几行数据\n",
    "print(df_train.info()) # 输出训练集信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集是预先排过序的，下面的代码将其进行乱序排列：\n",
    "from sklearn.utils import shuffle # 导入乱序工具\n",
    "df_train = shuffle(df_train)\n",
    "df_test = shuffle(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   9.17  -29.55  -49.19 ...   22.86   55.46   58.34]\n",
      " [  -5.63  -11.97   -7.33 ...    1.64    2.09    4.24]\n",
      " [ -91.24  -88.34  -89.36 ...  -12.44   -5.5    -7.75]\n",
      " ...\n",
      " [-112.91 -108.05 -149.54 ...   52.41   23.74   56.08]\n",
      " [  -3.27   -8.6    -9.61 ...    2.81   -3.27    5.53]\n",
      " [ -53.26  -27.11  -25.67 ...   17.07   -7.19   11.14]]\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train.iloc[:,1:].values # 构建特征集（训练）\n",
    "y_train = df_train.iloc[:,0].values # 构建标签集（训练）\n",
    "X_test = df_test.iloc[:,1:].values # 构建特征集（测试）\n",
    "y_test = df_test.iloc[:,0].values # 构建标签集（测试）\n",
    "y_train = y_train - 1   # 标签转换成惯用的(0，1)分类\n",
    "y_test = y_test - 1\n",
    "print (X_train) # 打印训练集中的特征\n",
    "print (y_train) # 打印训练集中的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5087, 3197, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.expand_dims(X_train, axis=2) # 张量升阶，以满足序列数据集的要求\n",
    "X_test = np.expand_dims(X_test, axis=2) # 张量升阶，以满足序列数据集的要求\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential # 导入序贯模型\n",
    "from keras import layers # 导入所有类型的层\n",
    "from keras.optimizers import Adam # 导入优化器\n",
    "model = Sequential() # 序贯模型\n",
    "model.add(layers.Conv1D(32, kernel_size = 10, strides = 4,\n",
    "                    input_shape = (3197, 1))) # 1D CNN层\n",
    "model.add(layers.MaxPooling1D(pool_size = 4, strides = 2)) # 池化层\n",
    "model.add(layers.GRU(256, return_sequences=True)) # 关键，GRU层要够大\n",
    "model.add(layers.Flatten()) # 展平\n",
    "model.add(layers.Dropout(0.5)) # Dropout层\n",
    "model.add(layers.BatchNormalization()) # 批标准化\n",
    "model.add(layers.Dense(1, activation='sigmoid')) # 分类输出层\n",
    "opt = Adam(lr = 0.0001, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "model.compile(optimizer=opt, # 优化器\n",
    "                            loss = 'binary_crossentropy', # 交叉熵\n",
    "                            metrics = ['accuracy']) # 准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,y_train, # 训练集\n",
    "                    validation_split = 0.2, # 部分训练集数据拆分成验证集\n",
    "                    batch_size = 128, # 批量大小\n",
    "                    epochs = 4, # 训练轮次\n",
    "                    shuffle = True) # 乱序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.8.3 输出阈值的调整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report # 分类报告\n",
    "from sklearn.metrics import confusion_matrix # 混淆矩阵\n",
    "y_prob = model.predict(X_test) # 对测试集进行预测\n",
    "y_pred =  np.where(y_prob > 0.5, 1, 0) #将概率值转换成真值\n",
    "cm = confusion_matrix(y_pred, y_test)\n",
    "print('Confusion matrix:\\n', cm, '\\n')\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "阈值调整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =  np.where(y_prob > 0.15, 1, 0) # 进行阈值调整\n",
    "cm = confusion_matrix(y_pred, y_test) \n",
    "print('Confusion matrix:\\n', cm, '\\n')\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.8.4 使用函数式API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers # 导入各种层\n",
    "from keras.models import Model # 导入模型\n",
    "from keras.optimizers import Adam # 导入Adam优化器\n",
    "input = layers.Input(shape=(3197, 1)) # Input\n",
    "# 通过函数式API构建模型\n",
    "x = layers.Conv1D(32, kernel_size=10, strides=4)(input)\n",
    "x = layers.MaxPooling1D(pool_size=4, strides=2)(x)\n",
    "x = layers.GRU(256, return_sequences=True)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "output = layers.Dense(1, activation='sigmoid')(x) # Output\n",
    "model = Model(input, output) \n",
    "model.summary() # 显示模型的输出\n",
    "opt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, decay=0.01) # 设置优化器\n",
    "model.compile(optimizer=opt, # 优化器\n",
    "              loss = 'binary_crossentropy', # 交叉熵\n",
    "              metrics=['accuracy']) # 准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "双向RNN模型:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先在给输入数据集升维之前数据集进行逆序：\n",
    "X_train_rev = [X[::-1] for X in X_train]\n",
    "X_test_rev = [X[::-1] for X in X_test]\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_train_rev = np.expand_dims(X_train_rev, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)\n",
    "X_test_rev = np.expand_dims(X_test_rev, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再构建多头网络：\n",
    "# 构建正向网络\n",
    "input_1 = layers.Input(shape=(3197, 1))\n",
    "x = layers.GRU(32, return_sequences=True)(input_1)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "# 构建逆向网络\n",
    "input_2 = layers.Input(shape=(3197, 1))\n",
    "y = layers.GRU(32, return_sequences=True)(input_2)\n",
    "y = layers.Flatten()(y)\n",
    "y = layers.Dropout(0.5)(y)\n",
    "# 连接两个网络\n",
    "z = layers.concatenate([x, y])\n",
    "output = layers.Dense(1, activation='sigmoid')(z)\n",
    "model = Model([input_1,input_2], output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit([X_train, X_train_rev], y_train, # 训练集\n",
    "                    validation_split = 0.2, # 部分训练集数据拆分成验证集\n",
    "                    batch_size = 128, # 批量大小\n",
    "                    epochs = 1, # 训练轮次\n",
    "                    shuffle = True) # 乱序"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96bbb65fb5df4d9cc0d3b437c46ecfe8c6742e111c114025f0cea31b14306341"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('Vuean_ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
